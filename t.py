import json
import shutil

from fastapi import FastAPI, UploadFile, File, HTTPException
import uvicorn
import soundfile
import os
import logging
from fastapi.middleware.cors import CORSMiddleware
from tempfile import NamedTemporaryFile
from funasr import AutoModel
from starlette.responses import StreamingResponse

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("FunASR")

# æ¨¡å‹å‚æ•°ï¼ˆä¸ä½ åŸå§‹ä»£ç ä¸€è‡´ï¼‰
chunk_size = [0, 10, 5]  # [0, 10, 5] å¯¹åº”600msåˆ†å—
encoder_chunk_look_back = 4
decoder_chunk_look_back = 1

# åˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…åŠ è½½ä¸€æ¬¡ï¼‰
# ä¿®æ”¹ä¸ºæœ¬åœ°æ¨¡å‹è·¯å¾„
model_path = "./models/paraformer-zh-streaming"

logger.info(f"ğŸ§  åŠ è½½æœ¬åœ° FunASR æ¨¡å‹: {model_path} ...")
model = AutoModel(model=model_path)

app = FastAPI()

# å…è®¸è·¨åŸŸï¼ˆå‰ç«¯è®¿é—®éœ€è¦ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å®é™…ç”Ÿäº§ç¯å¢ƒå»ºè®®é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼ˆæ ¹æ®soundfileæ”¯æŒçš„æ ¼å¼æ‰©å±•ï¼‰
ALLOWED_EXTENSIONS = {".wav", ".flac", ".ogg"}


def allowed_file(filename: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦åˆæ³•"""
    ext = os.path.splitext(filename)[1].lower()
    return ext in ALLOWED_EXTENSIONS

@app.post("/transcribe")
async def asr_stream_endpoint(file: UploadFile = File(...)):
    """æ¥æ”¶éŸ³é¢‘æ–‡ä»¶å¹¶æµå¼è¿”å›æ¯ä¸ª chunk çš„è¯†åˆ«ç»“æœ"""

    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

    with NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as temp_file:
        temp_file.write(await file.read())
        temp_path = temp_file.name
        print("temp_path{}", temp_path)
    try:
        speech, sample_rate = soundfile.read(temp_path)
        chunk_stride = chunk_size[1] * 960
        cache = {}
        total_chunk_num = int((len(speech) - 1) / chunk_stride + 1)

        # ä½¿ç”¨ FastAPI çš„ StreamingResponse
        async def generate():
            for i in range(total_chunk_num):
                start = i * chunk_stride
                end = (i + 1) * chunk_stride
                speech_chunk = speech[start:end]
                is_final = (i == total_chunk_num - 1)

                res = model.generate(
                    input=speech_chunk,
                    cache=cache,
                    is_final=is_final,
                    chunk_size=chunk_size,
                    encoder_chunk_look_back=encoder_chunk_look_back,
                    decoder_chunk_look_back=decoder_chunk_look_back
                )
                # æå– text å­—æ®µå†…å®¹
                if res and isinstance(res, list):
                    texts = [item.get("text", "") for item in res]
                    full_text = " ".join(texts).strip()  # æˆ–è€…ç”¨ ''.join æ‹¼æ¥æˆå®Œæ•´å¥å­
                else:
                    full_text = ""
                print("full_text{}", full_text)
                yield json.dumps({"text": full_text}, ensure_ascii=False) + "\n"

        return StreamingResponse(generate(), media_type="application/json")

    except Exception as e:
        logger.error(f"è¯†åˆ«å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯: {str(e)}")

    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8081)
